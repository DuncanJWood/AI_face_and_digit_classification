{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from parse import parse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = parse('facedata/facedatatrain', 'facedata/facedatatrainlabels', True)\n",
    "validation_images, validation_labels = parse('facedata/facedatavalidation', 'facedata/facedatavalidationlabels', True)\n",
    "test_images, test_labels = parse('facedata/facedatatest', 'facedata/facedatatestlabels', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51884701 0.48115299]\n"
     ]
    }
   ],
   "source": [
    "base_rate_true = np.bincount(train_labels)/train_labels.shape[0]\n",
    "print(base_rate_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(100)\n",
    "bias = 0\n",
    "kernel = np.ones((7,6))\n",
    "images = np.swapaxes(np.swapaxes(train_images.astype(np.float64), 0, 2), 0, 1)\n",
    "dst = cv2.filter2D(src = images, ddepth = -1, kernel = kernel, anchor = (0,0))\n",
    "zones = dst[::7,::6,:]\n",
    "for k in range(1000):\n",
    "    for i in range(0, 450):\n",
    "        arr = zones[:,:,i].ravel()\n",
    "        b = np.dot(weights, arr) +bias\n",
    "        if b < 0 and train_labels[i] == True:\n",
    "            for j in range(0,99):\n",
    "                    weights[j] += arr[j]\n",
    "            bias += 1\n",
    "        elif b >= 0 and train_labels[i] == False:\n",
    "            for j in range(0,99):\n",
    "                weights[j] -= arr[j]\n",
    "            bias -= 1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5182724252491694\n"
     ]
    }
   ],
   "source": [
    "tally = 0\n",
    "vimages = np.swapaxes(np.swapaxes(validation_images.astype(np.float64), 0, 2), 0, 1)\n",
    "vdst = cv2.filter2D(src = vimages, ddepth = -1, kernel = kernel, anchor = (0,0))\n",
    "vzones = vdst[::7,::6,:]\n",
    "\n",
    "for i in range(0,300):\n",
    "    arr = vzones[:,:,i].ravel()\n",
    "    b = np.dot(weights, arr) + bias \n",
    "    if (b >= 0 and validation_labels[i] == True) or (b < 0 and validation_labels[i] == False):\n",
    "        tally += 1\n",
    "print(tally/301)        \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21522df79a5f2f7576e87cd4971b777eef95bcbd6396c0a74d6cd78603fae977"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
